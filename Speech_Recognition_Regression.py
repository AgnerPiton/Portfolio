# -*- coding: utf-8 -*-
"""MLcode1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1D365AgkLP8Qjl4Rz8yW2nN1KbpsRgit5
"""

import numpy as np
import pandas as pd

feat = np.load("/content/drive/My Drive/ML/feat.npy", allow_pickle = True)
train = pd.read_csv("/content/drive/My Drive/ML/train.csv")[0:94823]
path = np.load("/content/drive/My Drive/ML/path.npy")
test= pd.read_csv('/content/drive/My Drive/ML/test.csv')

#arrange the features into the right index according to train
index_list = []
new_feat = []

for i in range(94823):
    for expression in enumerate(path == train.values[i][0]):
        if expression[1] == True:
            index_list.append(expression[0])
            
for element in index_list:
    new_feat.append(feat[element])
    
new_feat = np.array(new_feat)

# Function to get only the data with shape 99,13 (most of the data)

def shaper(data):
    lista =[]
    for row in data:
        if row.shape == data[0].shape:
                lista.append(row)
    return np.asarray(lista)
        
feature3=shaper(new_feat)

# Index features to the corresponding words on the train file

data = pd.DataFrame({'path':path, 'features':feat})
combined2 =pd.merge(train,data, on="path")
index1=np.where(list([row.shape==feature3[0].shape for row in feature3]))[0]
labels1=combined2.word[index1]
labels12=pd.DataFrame(labels1)
labels_train=np.array(labels12.word.tolist())

# check if labels and features have the same length

len(labels_train) == len(feature3)

from sklearn.preprocessing import LabelEncoder
from keras.utils import to_categorical

# Convert features and corresponding classification labels into numpy arrays
X = feature3
y = labels_train

# Encode the classification labels
le = LabelEncoder()
yy = to_categorical(le.fit_transform(y)) 

# split the dataset 
from sklearn.model_selection import train_test_split 

x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.15, random_state = 42)

# Reference: https://medium.com/@mikesmales/sound-classification-using-deep-learning-8bc2aa1990b7

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten
from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D
from keras.optimizers import Adam
from keras.utils import np_utils
from sklearn import metrics 

num_rows = 99
num_columns = 13
num_channels = 1

#Reshape to the correct number of dimensions

x_train = x_train.reshape(x_train.shape[0], num_rows, num_columns, num_channels)
x_test = x_test.reshape(x_test.shape[0], num_rows, num_columns, num_channels)

num_labels = yy.shape[1]
filter_size = 2

# Construct model 
model = Sequential()
model.add(Conv2D(filters=256, kernel_size=(3,3), input_shape=(num_rows, num_columns, num_channels), activation='relu'))
model.add(Dropout(0.5))
model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu'))
model.add(Conv2D(filters=256, kernel_size=(3,3), activation='relu'))
model.add(Dropout(0.5))
model.add(Conv2D(filters=512, kernel_size=(3,3), activation='relu'))
model.add(Dense(1024, activation='relu'))
model.add(GlobalAveragePooling2D())

model.add(Dense(num_labels, activation='softmax'))

# Compile the model
optimizer = Adam(lr=0.001)
model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=optimizer)

# Display model architecture summary 
model.summary()

# Calculate pre-training accuracy 
score = model.evaluate(x_test, y_test, verbose=1)
accuracy = 100*score[1]

print("Pre-training accuracy: %.4f%%" % accuracy)

#Train the model

from datetime import datetime 

num_epochs = 20
num_batch_size = 128

start = datetime.now()

model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test),  verbose=1)


duration = datetime.now() - start
print("Training completed in time: ", duration)

# Evaluate the model on the training and validation set
score = model.evaluate(x_train, y_train, verbose=0)
print("Training Accuracy: ", score[1])

score = model.evaluate(x_test, y_test, verbose=0)
print("Testing Accuracy: ", score[1])

#arrange the features into the right index according to the test file
index_list = []
new_feat = []

for i in range(len(test)):
    for expression in enumerate(path == test.values[i][0]):
        if expression[1] == True:
            index_list.append(expression[0])
            
for element in index_list:
    new_feat.append(feat[element])
    
new_feat = np.array(new_feat)

#pad the features so that they all have the same size
#features are padded with zero, because empty spaces resemble no sound
pad_feat = []

for i in range (new_feat.shape[0]):
    if new_feat[i].shape != (99,13):
        rows = 99 - new_feat[i].shape[0]
        columns = 13 - new_feat[i].shape[1]
        pad_feat.append(np.pad(new_feat[i], ((0, rows), (0, columns)), 'constant', constant_values = 0))
    else:
        pad_feat.append(new_feat[i])
    
test_data = np.array(pad_feat)

#check if all features have shape after padding
for i in range(len(test_data)):
    if test_data[i].shape != (99,13):
        print(new_feat[i].shape)
print("all features have the same shape")

# Do the predictions for the test data

test_data=test_data.reshape(test_data.shape[0], num_rows, num_columns, num_channels)

predictions=model.predict(test_data)
predictions=np.argmax(predictions,axis=1)
predictions=le.inverse_transform(predictions)

# Save the predictions in the appropriate format

np.savetxt('/content/drive/My Drive/ML/predictions.csv',predictions, fmt='%s')
word = pd.read_csv("/content/drive/My Drive/ML/predictions.csv", header = None)
test['word'] = word
pd.DataFrame.to_csv(test, '/content/drive/My Drive/ML/result.csv', index = False)
